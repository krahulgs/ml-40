{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "616c09c3-32c2-421b-a481-ddcf87f6e6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/aayushi.chowla/OneDrive - Hero Corporate Service Private Limited/Desktop/Renewal_data/Testrenewals.csv\", usecols=[\n",
    "    \"Gender\", \"Age\", \"Marital Status\", \"RTO Name\", \"Vehicle Type\", \"Vechile Age\", \n",
    "    \"IC Name\", \"Is Online\", \"Customer Type\", \"City Name\", \"PIN\", \"Premium Amount\", \n",
    "    \"State Name\", \"Policy Number\", \"Model Name\", \"Policy Source\", \"Frame Number\", \"Renewed\", \"Policy Type\"\n",
    "], low_memory=False)\n",
    "\n",
    "X = df.drop(\"Renewed\", axis=1)\n",
    "y = df[\"Renewed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "645a04fa-ffbe-4357-94c2-943ef9f17b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [\"Age\", \"Premium Amount\"]  # Add more if needed\n",
    "cat_cols = [\n",
    "    \"Gender\", \"Marital Status\", \"RTO Name\", \"Vehicle Type\", \"Vechile Age\", \n",
    "    \"IC Name\", \"Is Online\", \"Customer Type\", \"City Name\", \"PIN\", \"State Name\", \n",
    "    \"Policy Number\", \"Model Name\", \"Policy Source\", \"Frame Number\", \"Policy Type\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_imputer = SimpleImputer(strategy=\"mean\")\n",
    "X_train_num = pd.DataFrame(num_imputer.fit_transform(X_train[num_cols]), columns=num_cols)\n",
    "X_test_num = pd.DataFrame(num_imputer.transform(X_test[num_cols]), columns=num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "X_train_cat = pd.DataFrame(cat_imputer.fit_transform(X_train[cat_cols]), columns=cat_cols)\n",
    "X_test_cat = pd.DataFrame(cat_imputer.transform(X_test[cat_cols]), columns=cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "X_train_cat_enc = pd.DataFrame(\n",
    "    encoder.fit_transform(X_train_cat),\n",
    "    columns=encoder.get_feature_names_out(cat_cols)\n",
    ")\n",
    "X_test_cat_enc = pd.DataFrame(\n",
    "    encoder.transform(X_test_cat),\n",
    "    columns=encoder.get_feature_names_out(cat_cols)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full = pd.concat([X_train_num.reset_index(drop=True), X_train_cat_enc.reset_index(drop=True)], axis=1)\n",
    "X_test_full = pd.concat([X_test_num.reset_index(drop=True), X_test_cat_enc.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_full[num_cols] = scaler.fit_transform(X_train_full[num_cols])\n",
    "X_test_full[num_cols] = scaler.transform(X_test_full[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg, pos = np.bincount(y_train)\n",
    "scale_pos_weight = neg / pos\n",
    "model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=4,\n",
    "    eval_metric='logloss',\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[264 190]\n",
      " [211 335]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.58      0.57       454\n",
      "           1       0.64      0.61      0.63       546\n",
      "\n",
      "    accuracy                           0.60      1000\n",
      "   macro avg       0.60      0.60      0.60      1000\n",
      "weighted avg       0.60      0.60      0.60      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_full, y_train)\n",
    "y_pred = model.predict(X_test_full)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b84f20f5-4f6c-4265-b832-87c0ec53f985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After model training\n",
    "feature_names = X_train_full.columns.tolist()\n",
    "\n",
    "# Save them\n",
    "import joblib\n",
    "joblib.dump(feature_names, \"xgb_feature_names.pkl\")\n",
    "\n",
    "# Load and reuse later\n",
    "loaded_feature_names = joblib.load(\"xgb_feature_names.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8868b2fd-57c0-4d2d-bfe0-428460ff8514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age  Premium Amount Gender Marital Status     RTO Name Vehicle Type  \\\n",
      "0   48            1387      M              M  GARIYABANDH            O   \n",
      "1   39            1391      F              M       Raipur            O   \n",
      "2   47            1517      M              M       Raipur            O   \n",
      "3   53            1302      M              M       Raipur            O   \n",
      "4   35            1519      F              M       Raipur            O   \n",
      "\n",
      "   Vechile Age                             IC Name Is Online Customer Type  \\\n",
      "0            7     United India Insurance Co. Ltd.         N             I   \n",
      "1           10     United India Insurance Co. Ltd.         N             I   \n",
      "2            8     United India Insurance Co. Ltd.         N             I   \n",
      "3           12  Universal  Sompo general insurance         N             I   \n",
      "4            7  Universal  Sompo general insurance         N             I   \n",
      "\n",
      "     City Name     PIN   State Name         Policy Number  \\\n",
      "0  GARIYABANDH  492001  CHHATISGARH  04010031230160740995   \n",
      "1        Rajim  493881  CHHATISGARH  04010031240160000285   \n",
      "2       Raipur  492001  CHHATISGARH  04010031240160000151   \n",
      "3       Raipur  492001  CHHATISGARH  2312/72452600/00/000   \n",
      "4       Raipur  492001  CHHATISGARH  2312/72467043/00/000   \n",
      "\n",
      "                 Model Name Policy Source       Frame Number Policy Type  \\\n",
      "0  PASSION PRO -  PPRJDRSCC        Dealer  MBLHAR185HHM02912           C   \n",
      "1     Pleasure PLN BDR SMCR        Dealer  MBLJF16EHEGF13475           C   \n",
      "2              PASSION PR O        Dealer  MBLHA10BSGHM08236           C   \n",
      "3          SPLENDOR PRO DRS        Dealer  MBLHA10ASDHB85993           C   \n",
      "4      PLEASURE (PLNDDRSCC)        Dealer  MBLJFW020HGK01732           C   \n",
      "\n",
      "   Renewal_Probability  Predicted_Renewal  \n",
      "0             0.485460                  0  \n",
      "1             0.470105                  0  \n",
      "2             0.622689                  1  \n",
      "3             0.652076                  1  \n",
      "4             0.585488                  1  \n"
     ]
    }
   ],
   "source": [
    "# Load new data\n",
    "df = pd.read_csv(\"C:/Users/aayushi.chowla/OneDrive - Hero Corporate Service Private Limited/Desktop/Renewal_data/Testing.csv\")\n",
    "\n",
    "# --- Imputation ---\n",
    "\n",
    "num_cols = [\"Age\", \"Premium Amount\"]  # Add more if needed\n",
    "cat_cols = [\n",
    "    \"Gender\", \"Marital Status\", \"RTO Name\", \"Vehicle Type\", \"Vechile Age\", \n",
    "    \"IC Name\", \"Is Online\", \"Customer Type\", \"City Name\",\"PIN\", \"State Name\", \n",
    "    \"Policy Number\", \"Model Name\", \"Policy Source\", \"Frame Number\", \"Policy Type\"\n",
    "]\n",
    "\n",
    "# Filter only the columns used during training\n",
    "all_required_columns = num_cols + cat_cols\n",
    "new_df = df[all_required_columns]\n",
    "\n",
    "# Impute missing values\n",
    "new_num = pd.DataFrame(num_imputer.transform(new_df[num_cols]), columns=num_cols)\n",
    "new_cat = pd.DataFrame(cat_imputer.transform(new_df[cat_cols]), columns=cat_cols)\n",
    "\n",
    "# Encode\n",
    "new_cat_enc = pd.DataFrame(\n",
    "    encoder.transform(new_cat),\n",
    "    columns=encoder.get_feature_names_out(cat_cols)\n",
    ")\n",
    "# Predict probabilities\n",
    "predicted_probs = model.predict_proba(new_full)[:, 1]\n",
    "# Add to original DataFrame\n",
    "new_df[\"Renewal_Probability\"] = predicted_probs\n",
    "\n",
    "\n",
    "# Separate features\n",
    "new_num = pd.DataFrame(num_imputer.transform(new_df[num_cols]), columns=num_cols)\n",
    "new_cat = pd.DataFrame(cat_imputer.transform(new_df[cat_cols]), columns=cat_cols)\n",
    "\n",
    "# --- Encoding ---\n",
    "new_cat_enc = pd.DataFrame(\n",
    "    encoder.transform(new_cat),\n",
    "    columns=encoder.get_feature_names_out(cat_cols)\n",
    ")\n",
    "\n",
    "# --- Combine numeric and encoded categorical ---\n",
    "new_full = pd.concat([new_num.reset_index(drop=True), new_cat_enc.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# --- Scale numeric features ---\n",
    "new_full[num_cols] = scaler.transform(new_full[num_cols])\n",
    "\n",
    "# --- Predict ---\n",
    "predictions = model.predict(new_full)\n",
    "new_df[\"Predicted_Renewal\"] = predictions\n",
    "\n",
    "# See result\n",
    "print(new_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04e7794e-2a3e-4388-9bff-d38f33dcefc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv(\"C:/Users/aayushi.chowla/OneDrive - Hero Corporate Service Private Limited/Desktop/Renewal_data/Predicted.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f31a27f-75a6-4495-8d17-d75482ca6549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-import libraries after code execution environment reset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Simulating the filtered DataFrame (would normally come from model predictions)\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "new_df = pd.DataFrame({\n",
    "    \"Age\": np.random.randint(18, 70, size=n_samples),\n",
    "    \"Premium Amount\": np.random.randint(5000, 20000, size=n_samples),\n",
    "    \"Renewal_Probability\": np.random.uniform(0.5, 1.0, size=n_samples)  # only above 50%\n",
    "})\n",
    "\n",
    "# Add Predicted_Renewal column (1 if prob >= 0.5)\n",
    "new_df[\"Predicted_Renewal\"] = (new_df[\"Renewal_Probability\"] >= 0.5).astype(int)\n",
    "\n",
    "# Filter those with Renewal_Probability >= 0.5\n",
    "df_filtered = new_df[new_df[\"Renewal_Probability\"] >= 0.5].copy()\n",
    "\n",
    "# Define 5 clusters: 50-60, 60-70, 70-80, 80-90, 90-100\n",
    "bins = [0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "labels = [\"50-60%\", \"60-70%\", \"70-80%\", \"80-90%\", \"90-100%\"]\n",
    "df_filtered[\"Renewal_Cluster\"] = pd.cut(df_filtered[\"Renewal_Probability\"], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "# Save to Excel \n",
    "df_filtered.to_csv(\"C:/Users/aayushi.chowla/OneDrive - Hero Corporate Service Private Limited/Desktop/Renewal_data/Clustered Renewals.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6430d1d1-a5de-4f3f-8bc7-fe770b6e9a55",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Policy Number'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 19\u001b[0m\n\u001b[0;32m     11\u001b[0m filtered_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRenewal_Cluster\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mcut(\n\u001b[0;32m     12\u001b[0m     filtered_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRenewal_Probability\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     13\u001b[0m     bins\u001b[38;5;241m=\u001b[39mbins,\n\u001b[0;32m     14\u001b[0m     labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[0;32m     15\u001b[0m     include_lowest\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     16\u001b[0m )\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Select desired columns\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m clustered_df \u001b[38;5;241m=\u001b[39m filtered_df[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPolicy Number\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRenewal_Probability\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRenewal_Cluster\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[0;32m     21\u001b[0m output_path\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Policy Number'] not in index\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define bins and labels\n",
    "bins = [0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "labels = [\"50-60%\", \"60-70%\", \"70-80%\", \"80-90%\", \"90-100%\"]\n",
    "\n",
    "# Filter rows with probability > 0.5\n",
    "filtered_df = new_df[new_df[\"Renewal_Probability\"] > 0.5].copy()\n",
    "\n",
    "# Assign clusters\n",
    "filtered_df['Renewal_Cluster'] = pd.cut(\n",
    "    filtered_df['Renewal_Probability'],\n",
    "    bins=bins,\n",
    "    labels=labels,\n",
    "    include_lowest=False\n",
    ")\n",
    "\n",
    "# Select desired columns\n",
    "clustered_df = filtered_df[[\"Policy Number\", \"Renewal_Probability\", \"Renewal_Cluster\"]]\n",
    "\n",
    "output_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4bac656e-9262-4e36-91f8-f02b30600460",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clustered_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Save to Excel\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m clustered_df\u001b[38;5;241m.\u001b[39mto_csv(\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/aayushi.chowla/OneDrive - Hero Corporate Service Private Limited/Desktop/Renewal_data/Clusters.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m     index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m      5\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'clustered_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Save to Excel\n",
    "clustered_df.to_csv(\n",
    "    \"C:/Users/aayushi.chowla/OneDrive - Hero Corporate Service Private Limited/Desktop/Renewal_data/Clusters.csv\",\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b3e547-6d95-4a70-9271-4246edc3ea5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Step 1: Filter people with probability > 0.5\n",
    "high_prob_df = new_df[new_df[\"Renewal_Probability\"] > 0.5].copy()\n",
    "high_prob_features = new_full.loc[high_prob_df.index]  # Match corresponding features\n",
    "\n",
    "# Step 2: Perform clustering on the filtered feature set\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "clusters = kmeans.fit_predict(high_prob_features)\n",
    "\n",
    "# Step 3: Add cluster labels to the filtered DataFrame\n",
    "high_prob_df[\"Cluster\"] = clusters\n",
    "\n",
    "# Step 4: View cluster counts\n",
    "print(high_prob_df[\"Cluster\"].value_counts())\n",
    "\n",
    "# Step 5: Optional visualization\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=high_prob_df, x=\"Cluster\", palette=\"Set2\")\n",
    "plt.title(\"Distribution of People Likely to Renew (Clustered)\")\n",
    "plt.xlabel(\"Cluster\")\n",
    "plt.ylabel(\"Number of Customers\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = model.feature_importances_\n",
    "sorted_idx = np.argsort(importances)[::-1]\n",
    "\n",
    "# Limit to top N most important features\n",
    "top_n = 20\n",
    "top_features = sorted_idx[:top_n]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(top_n), importances[top_features][::-1], align='center')\n",
    "plt.yticks(range(top_n), X_train_full.columns[top_features][::-1])\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.title(\"Top 20 XGBoost Feature Importances\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab71f9b5-627d-495e-9e97-6f59a4909590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Load Data ---\n",
    "new_df = pd.read_csv(\"C:/Users/aayushi.chowla/OneDrive - Hero Corporate Service Private Limited/Desktop/Renewal_data/Testing.csv\", usecols=[\n",
    "    \"Gender\", \"Age\", \"Marital Status\", \"RTO Name\", \"Vehicle Type\", \"Vechile Age\", \n",
    "    \"IC Name\", \"Is Online\", \"Customer Type\", \"City Name\", \"PIN\", \"Premium Amount\", \n",
    "    \"State Name\", \"Policy Number\", \"Model Name\", \"Policy Source\", \"Frame Number\", \"Renewed\", \"Policy Type\"\n",
    "], low_memory=False)\n",
    "\n",
    "# --- Impute Missing Values ---\n",
    "new_num = pd.DataFrame(num_imputer.transform(new_df[num_cols]), columns=num_cols)\n",
    "new_cat = pd.DataFrame(cat_imputer.transform(new_df[cat_cols]), columns=cat_cols)\n",
    "\n",
    "# --- Encode Categorical Features ---\n",
    "new_cat_enc = pd.DataFrame(\n",
    "    encoder.transform(new_cat),\n",
    "    columns=encoder.get_feature_names_out(cat_cols)\n",
    ")\n",
    "\n",
    "# --- Combine & Scale ---\n",
    "new_full = pd.concat([new_num.reset_index(drop=True), new_cat_enc.reset_index(drop=True)], axis=1)\n",
    "new_full[num_cols] = scaler.transform(new_full[num_cols])\n",
    "\n",
    "# --- Predict Probabilities ---\n",
    "# XGBClassifier.predict_proba gives a 2D array: [[P(class 0), P(class 1)], ...]\n",
    "probabilities = model.predict_proba(new_full)\n",
    "\n",
    "# --- Add Predicted Probability of Renewal ---\n",
    "new_df[\"Renewal_Probability\"] = probabilities[:, 1]  # Probability of class '1' (renewed)\n",
    "new_df[\"Renewal_Probability\"] = probabilities[:, 0]  # Probability of class '1' (renewed)\n",
    "\n",
    "\n",
    "# --- Optional: Round for readability ---\n",
    "new_df[\"Renewal_Probability\"] = new_df[\"Renewal_Probability\"].round(4)\n",
    "\n",
    "# --- View results ---\n",
    "print(new_df[[\"Renewal_Probability\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8fd798-a668-4a81-932f-a92a68b50a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "\n",
    "xgb.plot_importance(model,max_num_features=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e292a4b7-ceb2-46b0-bfe5-c24922c17ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Step 2: Load the dataset\n",
    "df = pd.read_csv(\"C:/Users/aayushi.chowla/OneDrive - Hero Corporate Service Private Limited/Desktop/Renewal_data/Testing.csv\")  # Replace with your actual file name\n",
    "\n",
    "# Step 3: Clean + Select features (exclude ID-like columns)\n",
    "features = [\n",
    "    'Age']\n",
    "\n",
    "df = df[features + ['Renewed']].dropna()\n",
    "\n",
    "# Step 4: Encode Categorical\n",
    "cat_cols = df.select_dtypes(include='object').columns.tolist()\n",
    "num_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "num_cols.remove('Renewed')  # target not included in clustering\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "encoded_cat = pd.DataFrame(encoder.fit_transform(df[cat_cols]),\n",
    "                           columns=encoder.get_feature_names_out(cat_cols))\n",
    "\n",
    "# Step 5: Scale Numeric\n",
    "scaler = StandardScaler()\n",
    "scaled_num = pd.DataFrame(scaler.fit_transform(df[num_cols]), columns=num_cols)\n",
    "\n",
    "# Step 6: Combine all features\n",
    "X = pd.concat([scaled_num.reset_index(drop=True), encoded_cat.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Step 7: Apply KMeans\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "df['Cluster'] = kmeans.fit_predict(X)\n",
    "\n",
    "# Step 8: Visualize Average Feature Values by Cluster (bar plots)\n",
    "# We'll use numeric + one-hot-encoded column averages\n",
    "cluster_profiles = pd.DataFrame(X)\n",
    "cluster_profiles['Cluster'] = df['Cluster']\n",
    "avg_features = cluster_profiles.groupby('Cluster').mean().T\n",
    "\n",
    "# Plot top 15 most different features by variance between clusters\n",
    "top_diff_features = avg_features.var(axis=1).sort_values(ascending=False).head(15).index\n",
    "\n",
    "avg_features = avg_features.loc[top_diff_features]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(14, 8))\n",
    "avg_features.plot(kind='bar', figsize=(15, 6))\n",
    "plt.title(\"Top Feature Differences by Cluster\")\n",
    "plt.ylabel(\"Mean Value (Scaled)\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.legend(title=\"Cluster\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1e9ec8-d0b1-4170-8b06-1010be2cf4c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
